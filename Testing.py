import os
import pandas as pd
import numpy as np
import joblib
from tqdm import tqdm
from scipy.stats import skew, kurtosis
import tkinter as tk
from tkinter import ttk, filedialog
from functools import partial


try:
    from tensorflow.keras.models import load_model
except ImportError:

    def load_model(path):
        raise ImportError("TensorFlow/Keras is required for LSTM models.")

# ======================================
# å…¨å±€è®¾ç½®
# ======================================
TIME_STEPS = 10
LOADED_MODELS = None
LOADED_CMS = None
NEW_DATA_ROOT = None
ALL_ACTION_GROUPS = []


# ======================================
# åŸå§‹æ•°æ®å¤„ç†å‡½æ•°
# ======================================
def extract_features_from_csv(file_path):
    """ä» CSV æ–‡ä»¶ä¸­æå–ç‰¹å¾ã€‚"""
    try:
        # skiprows=8 ç¡®ä¿è·³è¿‡å‰ 8 è¡Œæµ‹è¯•ä¿¡æ¯
        df = pd.read_csv(file_path, skiprows=8, header=None)
        df.columns = ['time', 'cap']

        if len(df) < 1:
            return None

    except Exception:
        return None

    x = df['cap'].values
    # æå–ç»Ÿè®¡ç‰¹å¾
    feats = {
        'mean': np.mean(x), 'std': np.std(x), 'min': np.min(x),
        'max': np.max(x), 'range': np.ptp(x), 'skew': skew(x),
        'kurtosis': kurtosis(x), 'energy': np.sum(x ** 2) / len(x),
        'median': np.median(x), 'iqr': np.percentile(x, 75) - np.percentile(x, 25)
    }

    # æå–å¾®åˆ†ç‰¹å¾
    if len(df) > 1:
        dt = np.mean(np.diff(df['time'].values))
        deriv = np.gradient(x)
        feats['sampling_interval'] = dt
        feats['derivative_mean'] = np.mean(deriv)
        feats['derivative_std'] = np.std(deriv)
    else:
        feats['sampling_interval'] = 0
        feats['derivative_mean'] = 0
        feats['derivative_std'] = 0

    return feats


def create_sequences(X, y, time_steps):
    """å°†å¹³é¢ç‰¹å¾æ•°æ® X å’Œæ ‡ç­¾ y è½¬æ¢ä¸º LSTM æ‰€éœ€çš„ 3D åºåˆ—æ•°æ®ã€‚"""
    X_seq, y_seq = [], []
    X_array = X.values
    y_array = y

    for i in range(len(X) - time_steps + 1):
        X_seq.append(X_array[i:(i + time_steps)])
        y_seq.append(y_array[i + time_steps - 1])

    return np.array(X_seq), np.array(y_seq)


# ======================================
# æ¨¡å‹é¢„æµ‹å™¨å°è£…ç±»
# ======================================

class LSTMPredictor:
    def __init__(self, model_path, scaler_path, le_path, time_steps):
        self.model = load_model(model_path)
        self.scaler = joblib.load(scaler_path)
        self.le = joblib.load(le_path)
        self.time_steps = time_steps
        self.feature_names = self.scaler.feature_names_in_

    def predict_proba(self, X_df):
        X_df = X_df[self.feature_names]
        X_scaled = self.scaler.transform(X_df)
        X_scaled_df = pd.DataFrame(X_scaled, columns=X_df.columns)

        y_placeholder = pd.Series([0] * len(X_scaled_df), index=X_scaled_df.index)
        X_seq, _ = create_sequences(X_scaled_df, y_placeholder, self.time_steps)

        n_classes = len(self.le.classes_)
        full_probs = np.zeros((len(X_df), n_classes))

        if len(X_seq) == 0: return full_probs

        y_pred_probs_seq = self.model.predict(X_seq, verbose=0)

        # å¤„ç†åºåˆ—æ¨¡å‹å‰ time_steps - 1 ä¸ªæ ·æœ¬çš„ Normal å¡«å……
        if 'Normal' in self.le.classes_:
            normal_idx = np.where(self.le.classes_ == 'Normal')[0][0]
            for i in range(min(self.time_steps - 1, len(X_df))):
                full_probs[i, normal_idx] = 1.0

        start_idx = self.time_steps - 1
        end_idx = start_idx + len(y_pred_probs_seq)
        full_probs[start_idx:end_idx] = y_pred_probs_seq

        return full_probs


class RFPredictor:
    def __init__(self, model_path):
        self.model = joblib.load(model_path)
        self.le_classes = self.model.classes_
        self.feature_names = self.model.feature_names_in_

    def predict_proba(self, X_df):
        X_df = X_df[self.feature_names]
        return self.model.predict_proba(X_df)


# ======================================
# æ¨¡å‹åŠ è½½å’Œæ€§èƒ½å‡½æ•°
# ======================================
def load_all_models(saving_dir="saving"):
    """ä»ä¿å­˜ç›®å½•åŠ è½½æ‰€æœ‰éƒ¨ä»¶çš„é¢„æµ‹æ¨¡å‹å’Œè®­ç»ƒæ—¶çš„å½’ä¸€åŒ–æ··æ·†çŸ©é˜µã€‚"""
    MODELS = {}
    CMS = {}
    STRUCTURES = {
        "Seat belt": "RF",
        "Steering wheel": "RF",
        "Pedal": "RF",
        "Seat cushion": "LSTM"
    }

    if not os.path.isdir(saving_dir):
        raise FileNotFoundError(f"æ‰¾ä¸åˆ°æ¨¡å‹ä¿å­˜ç›®å½•: '{saving_dir}'ã€‚è¯·ç¡®ä¿æ¨¡å‹å·²è®­ç»ƒå¹¶ä¿å­˜åœ¨æ­¤ã€‚")

    for component, model_type in STRUCTURES.items():
        name = component.replace(" ", "_")
        cm_filename = f"{name}_{model_type}_CM_percent.csv"
        cm_path = os.path.join(saving_dir, cm_filename)

        try:
            # 1. åŠ è½½æ¨¡å‹
            if model_type == "RF":
                model_path = os.path.join(saving_dir, f"{name}_RF_model.pkl")
                MODELS[component] = RFPredictor(model_path)
            elif model_type == "LSTM":
                model_path = os.path.join(saving_dir, f"{name}_LSTM_model.h5")
                scaler_path = os.path.join(saving_dir, f"{name}_LSTM_scaler.pkl")
                le_path = os.path.join(saving_dir, f"{name}_LSTM_le.pkl")
                MODELS[component] = LSTMPredictor(model_path, scaler_path, le_path, TIME_STEPS)

            # 2. åŠ è½½æ··æ·†çŸ©é˜µ
            if os.path.exists(cm_path):
                cm_df = pd.read_csv(cm_path, index_col=0)
                cm_text = f"\n=== {component} (è®­ç»ƒé›†CM %) ===\n"
                cm_text += cm_df.to_string(
                    float_format=lambda x: f'{x:.2f}' if isinstance(x, (float, np.floating)) else str(x))
                CMS[component] = cm_text
            else:
                CMS[component] = f"\n=== {component} (è®­ç»ƒé›†CM %) ===\n æ‰¾ä¸åˆ°æ··æ·†çŸ©é˜µæ–‡ä»¶: {cm_filename}"

        except Exception as e:
            raise Exception(f"åŠ è½½ {component} æ¨¡å‹/CMå¤±è´¥: {e}")

    return MODELS, CMS


def apply_threshold_and_get_state(results, threshold=0.6):
    """
    åªè¦ä»»ä¸€é Normal çŠ¶æ€æ¦‚ç‡è¶…è¿‡é˜ˆå€¼ï¼Œåˆ™é‡‡ç”¨æ¦‚ç‡æœ€é«˜çš„é Normal çŠ¶æ€ä½œä¸ºæœ€ç»ˆç»“æœã€‚
    """
    final_states = {}
    for file_name, component_results in results.items():
        final_states[file_name] = {}
        for component, state_probs in component_results.items():
            final_state = "Normal"  # é»˜è®¤çŠ¶æ€
            max_prob = 0.0
            best_non_normal_state = "Normal"

            # ç¬¬ä¸€æ¬¡éå†ï¼šæ‰¾åˆ°æ¦‚ç‡æœ€é«˜çš„é Normal çŠ¶æ€åŠå…¶æ¦‚ç‡
            for state, prob in state_probs.items():
                if state != "Normal":
                    if prob > max_prob:
                        max_prob = prob
                        best_non_normal_state = state

            # ç¬¬äºŒæ¬¡åˆ¤æ–­ï¼šå¦‚æœæœ€é«˜çš„é Normal æ¦‚ç‡è¾¾åˆ°é˜ˆå€¼ (60% æˆ–æ›´é«˜)ï¼Œåˆ™é‡‡ç”¨è¯¥çŠ¶æ€
            if max_prob >= threshold:
                final_state = best_non_normal_state

            # å¦åˆ™ï¼Œä¿æŒé»˜è®¤çš„ "Normal"
            final_states[file_name][component] = final_state
    return final_states
# ======================================
# æ•°æ®åŠ è½½å’Œé¢„æµ‹ä¸»å‡½æ•°
# ======================================
def scan_action_groups(root_path):
    """æ‰«ææŒ‡å®šæ ¹ç›®å½•ï¼Œè¿”å›æ‰€æœ‰å”¯ä¸€çš„ CSV æ–‡ä»¶åï¼ˆåŠ¨ä½œç»„ IDï¼‰"""
    NEW_STRUCTURE_COMPONENTS = ["Seat belt", "Pedal", "Seat cushion", "Steering wheel"]
    unique_files = set()

    for component in NEW_STRUCTURE_COMPONENTS:
        comp_path = os.path.join(root_path, component)
        if not os.path.isdir(comp_path): continue
        for dirpath, dirnames, filenames in os.walk(comp_path):
            for file in filenames:
                if file.endswith(".csv"):
                    unique_files.add(file)

    return sorted(list(unique_files))


def load_new_data_and_predict(new_data_root, models, group_filter=None):
    """åŠ è½½æ•°æ®å¹¶é¢„æµ‹ï¼Œè¿”å›å¹³å‡æ¦‚ç‡å’Œæ ·æœ¬é¢„æµ‹è®¡æ•°ã€‚"""

    NEW_STRUCTURE = {
        "Seat belt": ["Belly", "Chest"],
        "Pedal": [""],
        "Seat cushion": ["1.1", "1.2", "2.1", "2.2"],
        "Steering wheel": ["3", "9"]
    }

    action_files = {}

    # é˜¶æ®µ 1: ç‰¹å¾æå–å’ŒæŒ‰åŠ¨ä½œåˆ†ç»„
    for component, channels in NEW_STRUCTURE.items():
        comp_path = os.path.join(new_data_root, component)
        if not os.path.isdir(comp_path): continue
        for channel in channels:
            dir_path = comp_path if channel == "" else os.path.join(comp_path, channel)
            if not os.path.isdir(dir_path): continue
            for file in os.listdir(dir_path):
                if not file.endswith(".csv"): continue
                if group_filter is not None and file != group_filter: continue
                full_path = os.path.join(dir_path, file)
                feats = extract_features_from_csv(full_path)
                if feats is None: continue
                feats_df = pd.DataFrame([feats])
                if file not in action_files:
                    action_files[file] = {comp: {} for comp in NEW_STRUCTURE.keys()}
                action_files[file][component][channel] = feats_df

    # é˜¶æ®µ 2: æ¦‚ç‡é¢„æµ‹å’Œè®¡æ•°
    action_results = {}
    sample_pred_counts = {}

    if not action_files:
        raise ValueError("åœ¨æ–°æ•°æ®æ ¹ç›®å½•ä¸­æœªæ‰¾åˆ°ä»»ä½•æœ‰æ•ˆçš„ CSV æ–‡ä»¶è¿›è¡Œå¤„ç†ã€‚")

    for file_name, component_data in tqdm(action_files.items(), desc=" æ­£åœ¨å¯¹åŠ¨ä½œç»„è¿›è¡Œé¢„æµ‹"):

        action_results[file_name] = {}
        sample_pred_counts[file_name] = {}

        for component, channel_data in component_data.items():

            if not channel_data: continue

            full_feature_df = pd.concat(channel_data.values(), ignore_index=True)
            model_predictor = models[component]

            # 1. è¿›è¡Œæ¦‚ç‡é¢„æµ‹
            probs_matrix = model_predictor.predict_proba(full_feature_df)

            # 2. ç¡®å®šæ ·æœ¬é¢„æµ‹çš„æœ€ç»ˆç±»åˆ« (å–æ¦‚ç‡æœ€é«˜çš„)
            predicted_encoded = np.argmax(probs_matrix, axis=1)

            # 3. è¿˜åŸä¸ºåŸå§‹æ ‡ç­¾
            classes = model_predictor.le.classes_.tolist() if hasattr(model_predictor,
                                                                      'le') else model_predictor.le_classes.tolist()
            predicted_labels = [classes[i] for i in predicted_encoded]

            # 4. ç»Ÿè®¡è®¡æ•°
            counts = pd.Series(predicted_labels).value_counts().to_dict()
            counts['__Total__'] = len(predicted_labels)
            sample_pred_counts[file_name][component] = counts

            # 5. è®¡ç®—éƒ¨ä»¶çš„å¹³å‡æ¦‚ç‡ (ç”¨äº 60% é˜ˆå€¼åˆ¤æ–­)
            avg_probs = np.mean(probs_matrix, axis=0)
            result = {classes[i]: avg_probs[i] for i in range(len(classes))}
            action_results[file_name][component] = result

    return action_results, sample_pred_counts


# ======================================
# GUI å›è°ƒå‡½æ•°
# ======================================
def load_models_for_gui(status_label, loading_button, cm_text_widget):
    """åœ¨ GUI ä¸­åŠ è½½æ‰€æœ‰æ¨¡å‹å’Œæ··æ·†çŸ©é˜µ"""
    global LOADED_MODELS, LOADED_CMS
    try:
        status_label.config(text="æ­£åœ¨åŠ è½½æ¨¡å‹å’Œæ··æ·†çŸ©é˜µ... è¯·ç¨å€™...", foreground="orange")
        status_label.winfo_toplevel().update()

        MODELS, CMS = load_all_models(saving_dir="saving")
        globals()['LOADED_MODELS'] = MODELS
        globals()['LOADED_CMS'] = CMS

        # æ˜¾ç¤ºæ··æ·†çŸ©é˜µ
        cm_text_widget.delete('1.0', tk.END)
        full_cm_text = "\n".join(CMS.values())
        cm_text_widget.insert(tk.END, full_cm_text)

        status_label.config(text="æ¨¡å‹å’Œæ··æ·†çŸ©é˜µåŠ è½½æˆåŠŸï¼", foreground="green")
        loading_button.config(state=tk.DISABLED)
    except Exception as e:
        status_label.config(text=f"åŠ è½½å¤±è´¥: {e}", foreground="red")
        globals()['LOADED_MODELS'] = None
        globals()['LOADED_CMS'] = None


def select_folder_and_scan(status_label, select_group_combobox, run_btn):
    """é€‰æ‹©æ–‡ä»¶å¤¹å¹¶æ‰«æåŠ¨ä½œç»„"""
    global NEW_DATA_ROOT, ALL_ACTION_GROUPS

    if LOADED_MODELS is None:
        status_label.config(text="è¯·å…ˆåŠ è½½æ¨¡å‹ï¼", foreground="red")
        return

    new_data_root = filedialog.askdirectory(title="é€‰æ‹©æ–°æ•°æ®æ ¹ç›®å½•")
    if not new_data_root:
        return

    globals()['NEW_DATA_ROOT'] = new_data_root

    try:
        status_label.config(text="æ­£åœ¨æ‰«æåŠ¨ä½œç»„...", foreground="blue")
        status_label.winfo_toplevel().update()

        globals()['ALL_ACTION_GROUPS'] = scan_action_groups(NEW_DATA_ROOT)

        if not ALL_ACTION_GROUPS:
            status_label.config(text="æœªæ‰¾åˆ°ä»»ä½•æœ‰æ•ˆçš„ CSV åŠ¨ä½œç»„ã€‚", foreground="red")
            select_group_combobox.set("")
            run_btn.config(state=tk.DISABLED)
            return

        status_label.config(
            text=f"å·²æ‰¾åˆ° {len(ALL_ACTION_GROUPS)} ä¸ªåŠ¨ä½œç»„ã€‚è¯·åœ¨ä¸‹æ‹‰åˆ—è¡¨ä¸­é€‰æ‹©ã€‚",
            foreground="green"
        )

    except Exception as e:
        status_label.config(text=f"æ‰«æé”™è¯¯: {e}", foreground="red")
        run_btn.config(state=tk.DISABLED)


def run_prediction(text_widget, status_label, selected_group_var):
    """è¿è¡Œæ‰€é€‰åŠ¨ä½œç»„çš„é¢„æµ‹ï¼Œå¹¶æ˜¾ç¤ºæ–‡æœ¬æŠ¥å‘Šã€‚"""
    global LOADED_MODELS, NEW_DATA_ROOT

    group_filter = selected_group_var.get()
    if group_filter == "":
        status_label.config(text="è¯·é€‰æ‹©ä¸€ä¸ªåŠ¨ä½œç»„ï¼", foreground="red")
        return

    status_label.config(text=f"æ­£åœ¨é¢„æµ‹åŠ¨ä½œç»„: {group_filter}...", foreground="blue")
    text_widget.delete('1.0', tk.END)
    status_label.winfo_toplevel().update()

    try:
        # 1. åŠ è½½æ•°æ®å¹¶é¢„æµ‹æ¦‚ç‡
        results_avg_prob, results_counts = load_new_data_and_predict(
            NEW_DATA_ROOT, LOADED_MODELS, group_filter=group_filter
        )

        file_name = list(results_counts.keys())[0]
        counts_data = results_counts[file_name]

        # 2. ç›´æ¥æ ¹æ®æ ·æœ¬é¢„æµ‹ç»Ÿè®¡ç»“æœç¡®å®šæœ€ç»ˆçŠ¶æ€
        final_states = {file_name: {}}
        for component in counts_data:
            counts = counts_data[component]
            total = counts.get('__Total__', 0)

            if total == 0:
                final_states[file_name][component] = "Normal"
                continue

            # æ‰¾åˆ°é Normal çŠ¶æ€ä¸­æ ·æœ¬æ•°æœ€é«˜çš„
            max_non_normal_count = -1
            best_state = "Normal"

            for state, count in counts.items():
                if state == '__Total__': continue

                if state != "Normal":
                    if count > max_non_normal_count:
                        max_non_normal_count = count
                        best_state = state
                elif count == total and total > 0:
                    # å¦‚æœæ‰€æœ‰æ ·æœ¬éƒ½æ˜¯ Normalï¼Œåˆ™ç¡®å®šä¸º Normal
                    best_state = "Normal"

            # æœ€ç»ˆåˆ¤å®šï¼šå¦‚æœæœ€é«˜çš„é Normal çŠ¶æ€æ ·æœ¬æ•°å¤§äºç­‰äº 60%
            threshold_count = total * 0.6
            if max_non_normal_count >= threshold_count:
                # é‡‡çº³æ ·æœ¬æ•°æœ€é«˜çš„é Normal çŠ¶æ€
                final_states[file_name][component] = best_state
            else:
                # å¦åˆ™ï¼Œåˆ¤æ–­ä¸º Normal (å³ä½¿ Normal æ ·æœ¬æ•°ä¸è¶³ 60%)
                final_states[file_name][component] = "Normal"

        states = final_states[file_name]

        # 3. æ ¼å¼åŒ–è¾“å‡º
        output_text = f"========== åŠ¨ä½œç»„: {file_name} ==========\n\n"
        output_text += "--- [A] æ ·æœ¬ç»Ÿè®¡é˜ˆå€¼åˆ¤å®šç»“æœ (æœ€ç»ˆåˆ¤æ–­) ---\n"

        # æ’å…¥çº¯æ–‡æœ¬éƒ¨åˆ†
        text_widget.insert(tk.END, output_text)

        for component in sorted(states.keys()):
            state = states[component]

            # æ ¼å¼åŒ–ç»„ä»¶åç§°å’Œå‰å¯¼ç¬¦
            prefix = "  - "
            component_name_part = f"{component:<15}:"

            # ç¡®å®šæ˜¾ç¤ºæ–‡æœ¬å’Œè¦åº”ç”¨çš„ Tag
            if state == "Normal":
                display_state_part = "ğŸ˜ğŸ˜€ æ­£å¸¸\n"
                tag_name = 'normal_tag'  # ç»¿è‰²åŠ ç²—
            else:
                # ç»Ÿä¸€å°†æ‰€æœ‰é Normal çŠ¶æ€è¯†åˆ«ä¸ºå§¿æ€å¼‚å¸¸ï¼Œå¹¶æ˜¾ç¤ºå…·ä½“çŠ¶æ€
                display_state_part = f"!!âš ï¸ å§¿æ€å¼‚å¸¸ ({state}) !!\n"
                tag_name = 'abnormal_tag'  # çº¢è‰²åŠ ç²—

            # æŒ‰é¡ºåºæ’å…¥æ–‡æœ¬å’Œåº”ç”¨ Tag
            text_widget.insert(tk.END, prefix)
            text_widget.insert(tk.END, component_name_part, ('normal_tag', 'abnormal_tag'))  # ä¿æŒç»„ä»¶åç§°é¢œè‰²ä¸­ç«‹æˆ–ä½¿ç”¨é»˜è®¤
            text_widget.insert(tk.END, display_state_part, tag_name)  # åº”ç”¨ç›®æ ‡é¢œè‰² Tag

        # 4. æ ¼å¼åŒ–è¾“å‡º (æ ·æœ¬åˆ†å¸ƒç»Ÿè®¡)
        output_text_b = "\n--- [B] æ ·æœ¬é¢„æµ‹åˆ†å¸ƒç»Ÿè®¡ (é¢„æµ‹å€¾å‘) ---\n"
        text_widget.insert(tk.END, output_text_b)

        for component in sorted(counts_data.keys()):
            counts = counts_data[component]
            total = counts.pop('__Total__', 0)

            output_text_comp = f"\n> {component} (æ€»æ ·æœ¬æ•°: {total})\n"
            text_widget.insert(tk.END, output_text_comp)

            if total > 0:
                sorted_counts = sorted(counts.items(), key=lambda item: item[1], reverse=True)

                for state, count in sorted_counts:
                    percentage = (count / total) * 100
                    output_line = f"  {state:<15} | {count:>5} æ ·æœ¬ | {percentage:>6.2f}%\n"
                    # è¿™é‡Œå¯ä»¥æ ¹æ®éœ€è¦ï¼Œåªå¯¹é Normal ä¸”å æ¯”é«˜çš„è¡Œåº”ç”¨çº¢è‰² tag
                    if state != "Normal" and percentage >= 60.0:
                        text_widget.insert(tk.END, output_line, 'normal_tag')
                    else:
                        text_widget.insert(tk.END, output_line)
            else:
                text_widget.insert(tk.END, "  (æ— æœ‰æ•ˆæ ·æœ¬)\n")

        output_text_end = "\n=========================================="
        text_widget.insert(tk.END, output_text_end)

        status_label.config(text=f"åŠ¨ä½œç»„ {group_filter} é¢„æµ‹å®Œæˆã€‚", foreground="green")

    except Exception as e:
        error_msg = f"é¢„æµ‹è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {type(e).__name__}: {e}"
        status_label.config(text=error_msg, foreground="red")
        text_widget.insert(tk.END, f"\n[ERROR] é”™è¯¯è¯¦æƒ…:\n{error_msg}")

# ======================================
# GUI ç»“æ„å®šä¹‰
# ======================================
def setup_gui():
    """è®¾ç½®ä¸» GUI ç•Œé¢"""
    root = tk.Tk()
    root.title("é©¾é©¶å§¿åŠ¿è¯†åˆ«éªŒè¯å·¥å…· ")
    root.geometry("800x650")  # ç¼©å°çª—å£å°ºå¯¸ï¼Œå› ä¸ºæ²¡æœ‰å›¾è¡¨

    style = ttk.Style()
    style.configure("TButton", padding=6, font=('Segoe UI', 10, 'bold'))
    style.configure("TLabel", font=('Segoe UI', 10))

    # --- ä¸»æ¡†æ¶ ---
    main_frame = ttk.Frame(root, padding="10")
    main_frame.pack(fill='both', expand=True)

    # --- é¡¶éƒ¨æ“ä½œåŒº ---
    top_panel = ttk.Frame(main_frame)
    top_panel.pack(fill='x')

    status_label = ttk.Label(top_panel, text="æ¬¢è¿ä½¿ç”¨ï¼è¯·å…ˆåŠ è½½æ¨¡å‹ã€‚", foreground="gray")
    status_label.pack(side=tk.LEFT, padx=5, pady=5)

    # --- ä¸­é—´ï¼šç»“æœ/CM æ˜¾ç¤ºåŒº (Notebook) ---
    notebook = ttk.Notebook(main_frame)
    notebook.pack(fill='both', expand=True, pady=10)

    # Tab 1: æ··æ·†çŸ©é˜µ (CM) é¡µé¢
    cm_frame = ttk.Frame(notebook, padding="10")
    notebook.add(cm_frame, text="æ¨¡å‹è®­ç»ƒæ€§èƒ½ (CM)")
    cm_text_widget = tk.Text(cm_frame, wrap=tk.WORD, font=("Consolas", 9), bd=2, relief=tk.SUNKEN)
    cm_text_widget.pack(fill='both', expand=True)

    # Tab 2: é¢„æµ‹ç»“æœé¡µé¢ (å•ä¸ªæ–‡æœ¬æ¡†)
    result_frame = ttk.Frame(notebook, padding="10")
    notebook.add(result_frame, text="æ–°æ•°æ®é¢„æµ‹ç»“æœ ")

    # å•ä¸ªæ–‡æœ¬æŠ¥å‘ŠåŒºåŸŸ
    text_widget = tk.Text(result_frame, wrap=tk.WORD, font=("Consolas", 10), bd=2, relief=tk.SUNKEN)
    text_widget.pack(fill='both', expand=True, side=tk.LEFT)
    text_widget.tag_configure('abnormal_tag',
                              foreground='red',
                              font=('Consolas', 10, 'bold'))
    # å®šä¹‰ç»¿è‰²æ­£å¸¸å­—ä½“æ ·å¼ (å¯é€‰ï¼Œä½†ä¸ºäº†å¯¹æ¯”åº¦æ›´å¥½)
    text_widget.tag_configure('normal_tag',
                              foreground='green',
                              font=('Consolas', 10, 'normal'))
    scrollbar = ttk.Scrollbar(result_frame, command=text_widget.yview)
    scrollbar.pack(side=tk.RIGHT, fill='y')
    text_widget.config(yscrollcommand=scrollbar.set)

    # --- åº•éƒ¨æ“ä½œåŒº ---
    bottom_bar = ttk.Frame(main_frame, padding="5")
    bottom_bar.pack(fill='x')

    # æ­¥éª¤ 3 å˜é‡å’Œç»„ä»¶
    ttk.Label(bottom_bar, text="3. é€‰æ‹©åŠ¨ä½œç»„:").pack(side=tk.LEFT, padx=(20, 5))
    selected_group_var = tk.StringVar()
    select_group_combobox = ttk.Combobox(
        bottom_bar, textvariable=selected_group_var, state='readonly', width=20)
    select_group_combobox['values'] = ALL_ACTION_GROUPS
    select_group_combobox.pack(side=tk.LEFT, padx=5)

    # æ­¥éª¤ 4 æŒ‰é’®ï¼šè¿è¡Œé¢„æµ‹ (æ³¨æ„ï¼šä¸å†éœ€è¦ chart_frame å‚æ•°)
    run_btn = ttk.Button(
        bottom_bar, text="4. è¿è¡Œé¢„æµ‹", state=tk.DISABLED,
        command=partial(run_prediction, text_widget, status_label, selected_group_var))
    run_btn.pack(side=tk.RIGHT, padx=10)

    # æ­¥éª¤ 1 æŒ‰é’®ï¼šåŠ è½½æ¨¡å‹
    load_btn = ttk.Button(top_panel, text="1. åŠ è½½æ¨¡å‹",
                          command=lambda: load_models_for_gui(status_label, load_btn, cm_text_widget))
    load_btn.pack(side=tk.RIGHT, padx=10, pady=5)

    # æ­¥éª¤ 2 æŒ‰é’®ï¼šé€‰æ‹©æ•°æ®æ–‡ä»¶å¤¹
    def update_combobox_after_scan(combobox, run_button):
        """è¾…åŠ©å‡½æ•°ï¼šæ‰«æåæ›´æ–° ComboBox çš„å€¼"""
        combobox['values'] = ALL_ACTION_GROUPS
        if ALL_ACTION_GROUPS:
            combobox.set(ALL_ACTION_GROUPS[0])
            run_button.config(state=tk.NORMAL)
        else:
            combobox.set("")
            run_button.config(state=tk.DISABLED)

    select_data_btn = ttk.Button(
        bottom_bar, text="2. é€‰æ‹©æ–°æ•°æ®æ–‡ä»¶å¤¹å¹¶æ‰«æåŠ¨ä½œç»„",
        command=lambda: [
            select_folder_and_scan(status_label, select_group_combobox, run_btn),
            update_combobox_after_scan(select_group_combobox, run_btn)]
    )
    select_data_btn.pack(side=tk.LEFT, padx=10)

    select_group_combobox.bind("<<ComboboxSelected>>", lambda e: run_btn.config(state=tk.NORMAL))

    root.mainloop()


# ======================================
# ä¸»å…¥å£
# ======================================
if __name__ == "__main__":
    print("--- é©¾é©¶å§¿åŠ¿è¯†åˆ«éªŒè¯å·¥å…·å·²å¯åŠ¨ ---")
    setup_gui()